@ARTICLE{1,
  author={Anand, Bhaskar and Senapati, Mrinal and Barsaiyan, Vivek and Rajalakshmi, Pachamuthu},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={LiDAR-INS/GNSS-Based Real-Time Ground Removal, Segmentation, and Georeferencing Framework for Smart Transportation}, 
  year={2021},
  volume={70},
  number={},
  pages={1-11},
  doi={10.1109/TIM.2021.3117661}}

@INPROCEEDINGS{2,
  author={Arora, Mehul and Wiesmann, Louis and Chen, Xieyuanli and Stachniss, Cyrill},
  booktitle={2021 European Conference on Mobile Robots (ECMR)}, 
  title={Mapping the Static Parts of Dynamic Scenes from 3D LiDAR Point Clouds Exploiting Ground Segmentation}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ECMR50962.2021.9568799}}

@ARTICLE{3,
  author={An, Yi and Liu, Wusong and Cui, Yunhao and Wang, Jinyu and Li, Xiusheng and Hu, Huosheng},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Multilevel Ground Segmentation for 3-D Point Clouds of Outdoor Scenes Based on Shape Analysis}, 
  year={2022},
  volume={71},
  number={},
  pages={1-13},
  doi={10.1109/TIM.2022.3154835}}  

@Article{4,
AUTHOR = {Gomes, Tiago and Matias, Diogo and Campos, André and Cunha, Luís and Roriz, Ricardo},
TITLE = {A Survey on Ground Segmentation Methods for Automotive LiDAR Sensors},
JOURNAL = {Sensors},
VOLUME = {23},
YEAR = {2023},
NUMBER = {2},
ARTICLE-NUMBER = {601},
URL = {https://www.mdpi.com/1424-8220/23/2/601},
PubMedID = {36679414},
ISSN = {1424-8220},
ABSTRACT = {In the near future, autonomous vehicles with full self-driving features will populate our public roads. However, fully autonomous cars will require robust perception systems to safely navigate the environment, which includes cameras, RADAR devices, and Light Detection and Ranging (LiDAR) sensors. LiDAR is currently a key sensor for the future of autonomous driving since it can read the vehicle&rsquo;s vicinity and provide a real-time 3D visualization of the surroundings through a point cloud representation. These features can assist the autonomous vehicle in several tasks, such as object identification and obstacle avoidance, accurate speed and distance measurements, road navigation, and more. However, it is crucial to detect the ground plane and road limits to safely navigate the environment, which requires extracting information from the point cloud to accurately detect common road boundaries. This article presents a survey of existing methods used to detect and extract ground points from LiDAR point clouds. It summarizes the already extensive literature and proposes a comprehensive taxonomy to help understand the current ground segmentation methods that can be used in automotive LiDAR sensors.},
DOI = {10.3390/s23020601}} 

@ARTICLE{5,
  author={Qian, Yeqiang and Wang, Xiaoliang and Chen, Ziqing and Wang, Chunxiang and Yang, Ming},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={Hy-Seg: A Hybrid Method for Ground Segmentation Using Point Clouds}, 
  year={2023},
  volume={8},
  number={2},
  pages={1597-1606},
  doi={10.1109/TIV.2022.3187008}}

@ARTICLE{6,
  author={Jiménez, Víctor and Godoy, Jorge and Artuñedo, Antonio and Villagra, Jorge},
  journal={IEEE Access}, 
  title={Ground Segmentation Algorithm for Sloped Terrain and Sparse LiDAR Point Cloud}, 
  year={2021},
  volume={9},
  number={},
  pages={132914-132927},
  doi={10.1109/ACCESS.2021.3115664}}

@INPROCEEDINGS{7,
  author={Narksri, Patiphon and Takeuchi, Eijiro and Ninomiya, Yoshiki and Morales, Yoichi and Akai, Naoki and Kawaguchi, Nobuo},
  booktitle={2018 21st International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={A Slope-robust Cascaded Ground Segmentation in 3D Point Cloud for Autonomous Vehicles}, 
  year={2018},
  volume={},
  number={},
  pages={497-504},
  doi={10.1109/ITSC.2018.8569534}}

@article{8,
title = {Static map generation from 3D LiDAR point clouds exploiting ground segmentation},
journal = {Robotics and Autonomous Systems},
volume = {159},
pages = {104287},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104287},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001762},
author = {Mehul Arora and Louis Wiesmann and Xieyuanli Chen and Cyrill Stachniss},
keywords = {Map cleaning, Ground segmentation},
abstract = {A clean and reliable map of the environment is key for a variety of robotic tasks including localization, path planning, and navigation. Dynamic objects are an inherent part of our world, but their presence often deteriorates the performance of various mapping algorithms. This not only makes it important but necessary to remove these dynamic points from the map before they can be used for other tasks such as path planning. In this paper, we address the problem of building maps of the static aspects of the world by detecting and removing dynamic points from the source point clouds. We target a map cleaning approach that removes the dynamic points and maintains a high quality map of the static part of the world. To this end, we propose a novel offline ground segmentation method and integrate it into the OctoMap to better distinguish between the moving objects and static road backgrounds. We evaluate our approach using SemanticKITTI for both, dynamic object removal and ground segmentation algorithms as well as on the Apollo dataset. The evaluation results show that our method outperforms the baseline methods in both tasks and achieves good performance in generating clean maps over different datasets without any change in the parameters.}
}

@article{9,
title = {FGSeg: Field-ground segmentation for agricultural robot based on LiDAR},
journal = {Computers and Electronics in Agriculture},
volume = {211},
pages = {107965},
year = {2023},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2023.107965},
url = {https://www.sciencedirect.com/science/article/pii/S0168169923003538},
author = {Eksan Firkat and Fan An and Bei Peng and Jinlai Zhang and Tayir Mijit and Arzigul Ahat and Jihong Zhu and Askar Hamdulla},
keywords = {LiDAR, Ground segmentation, Precision agriculture, Agricultural robot, Terrain analysis},
abstract = {Ground segmentation using LiDAR technology plays a vital role in the successful execution of several tasks in agricultural robotics, such as sowing, spraying, fertilizing, harvesting, and weeding. However, traditional ground segmentation algorithms are often designed for urban environments and are not suitable for complex and challenging agricultural field environments. Additionally, some of these algorithms depend on specific LiDAR sensors, limiting the range of options available for use in agricultural robots. To address these limitations, we introduce FGSeg, a ground segmentation algorithm designed specifically for the agricultural field environment. Our proposed method utilizes only the spatial features of the point cloud data, making it compatible with a wide range of LiDAR sensors. Additionally, FGSeg can effectively distinguish between horizontal and slope terrains, which is crucial for many agricultural operations. The results of extensive experiments demonstrate that our proposed algorithm outperforms existing ground segmentation algorithms in both field and urban environments, and its real-time performance makes it well-suited for practical applications in the agriculture industry.}
}
