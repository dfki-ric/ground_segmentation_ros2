@ARTICLE{1,
  author={Anand, Bhaskar and Senapati, Mrinal and Barsaiyan, Vivek and Rajalakshmi, Pachamuthu},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={{LiDAR-INS}/{GNSS}-Based Real-Time Ground Removal, Segmentation, and Georeferencing Framework for Smart Transportation}, 
  year={2021},
  volume={70},
  number={},
  pages={1-11},
  doi={10.1109/TIM.2021.3117661}}

@INPROCEEDINGS{2,
  author={Arora, Mehul and Wiesmann, Louis and Chen, Xieyuanli and Stachniss, Cyrill},
  booktitle={2021 European Conference on Mobile Robots (ECMR)}, 
  title={Mapping the Static Parts of Dynamic Scenes from 3D {LiDAR} Point Clouds Exploiting Ground Segmentation}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ECMR50962.2021.9568799}}

@ARTICLE{3,
  author={An, Yi and Liu, Wusong and Cui, Yunhao and Wang, Jinyu and Li, Xiusheng and Hu, Huosheng},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={Multilevel Ground Segmentation for 3-D Point Clouds of Outdoor Scenes Based on Shape Analysis}, 
  year={2022},
  volume={71},
  number={},
  pages={1-13},
  doi={10.1109/TIM.2022.3154835}}  

@Article{Gomes2023,
AUTHOR = {Gomes, Tiago and Matias, Diogo and Campos, André and Cunha, Luís and Roriz, Ricardo},
TITLE = {A Survey on Ground Segmentation Methods for Automotive LiDAR Sensors},
JOURNAL = {Sensors},
VOLUME = {23},
YEAR = {2023},
NUMBER = {2},
ARTICLE-NUMBER = {601},
URL = {https://www.mdpi.com/1424-8220/23/2/601},
PubMedID = {36679414},
ISSN = {1424-8220},
ABSTRACT = {In the near future, autonomous vehicles with full self-driving features will populate our public roads. However, fully autonomous cars will require robust perception systems to safely navigate the environment, which includes cameras, RADAR devices, and Light Detection and Ranging (LiDAR) sensors. LiDAR is currently a key sensor for the future of autonomous driving since it can read the vehicle&rsquo;s vicinity and provide a real-time 3D visualization of the surroundings through a point cloud representation. These features can assist the autonomous vehicle in several tasks, such as object identification and obstacle avoidance, accurate speed and distance measurements, road navigation, and more. However, it is crucial to detect the ground plane and road limits to safely navigate the environment, which requires extracting information from the point cloud to accurately detect common road boundaries. This article presents a survey of existing methods used to detect and extract ground points from LiDAR point clouds. It summarizes the already extensive literature and proposes a comprehensive taxonomy to help understand the current ground segmentation methods that can be used in automotive LiDAR sensors.},
DOI = {10.3390/s23020601}} 

@ARTICLE{5,
  author={Qian, Yeqiang and Wang, Xiaoliang and Chen, Ziqing and Wang, Chunxiang and Yang, Ming},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={{Hy-Seg}: A Hybrid Method for Ground Segmentation Using Point Clouds}, 
  year={2023},
  volume={8},
  number={2},
  pages={1597-1606},
  doi={10.1109/TIV.2022.3187008}}

@ARTICLE{Jimenez2021,
  author={Jiménez, Víctor and Godoy, Jorge and Artuñedo, Antonio and Villagra, Jorge},
  journal={IEEE Access}, 
  title={Ground Segmentation Algorithm for Sloped Terrain and Sparse {LiDAR} Point Cloud}, 
  year={2021},
  volume={9},
  number={},
  pages={132914-132927},
  doi={10.1109/ACCESS.2021.3115664}}

@INPROCEEDINGS{CascadedSeg,
  author={Narksri, Patiphon and Takeuchi, Eijiro and Ninomiya, Yoshiki and Morales, Yoichi and Akai, Naoki and Kawaguchi, Nobuo},
  booktitle={2018 21st International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={A Slope-robust Cascaded Ground Segmentation in 3D Point Cloud for Autonomous Vehicles}, 
  year={2018},
  volume={},
  number={},
  pages={497-504},
  doi={10.1109/ITSC.2018.8569534}}

@article{Arora2023,
title = {Static map generation from 3D {LiDAR} point clouds exploiting ground segmentation},
journal = {Robotics and Autonomous Systems},
volume = {159},
pages = {104287},
year = {2023},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104287},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001762},
author = {Mehul Arora and Louis Wiesmann and Xieyuanli Chen and Cyrill Stachniss},
keywords = {Map cleaning, Ground segmentation},
abstract = {A clean and reliable map of the environment is key for a variety of robotic tasks including localization, path planning, and navigation. Dynamic objects are an inherent part of our world, but their presence often deteriorates the performance of various mapping algorithms. This not only makes it important but necessary to remove these dynamic points from the map before they can be used for other tasks such as path planning. In this paper, we address the problem of building maps of the static aspects of the world by detecting and removing dynamic points from the source point clouds. We target a map cleaning approach that removes the dynamic points and maintains a high quality map of the static part of the world. To this end, we propose a novel offline ground segmentation method and integrate it into the OctoMap to better distinguish between the moving objects and static road backgrounds. We evaluate our approach using SemanticKITTI for both, dynamic object removal and ground segmentation algorithms as well as on the Apollo dataset. The evaluation results show that our method outperforms the baseline methods in both tasks and achieves good performance in generating clean maps over different datasets without any change in the parameters.}
}

@article{Firkat2023,
title = {{FGSeg}: Field-ground segmentation for agricultural robot based on {LiDAR}},
journal = {Computers and Electronics in Agriculture},
volume = {211},
pages = {107965},
year = {2023},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2023.107965},
url = {https://www.sciencedirect.com/science/article/pii/S0168169923003538},
author = {Eksan Firkat and Fan An and Bei Peng and Jinlai Zhang and Tayir Mijit and Arzigul Ahat and Jihong Zhu and Askar Hamdulla},
keywords = {LiDAR, Ground segmentation, Precision agriculture, Agricultural robot, Terrain analysis},
abstract = {Ground segmentation using LiDAR technology plays a vital role in the successful execution of several tasks in agricultural robotics, such as sowing, spraying, fertilizing, harvesting, and weeding. However, traditional ground segmentation algorithms are often designed for urban environments and are not suitable for complex and challenging agricultural field environments. Additionally, some of these algorithms depend on specific LiDAR sensors, limiting the range of options available for use in agricultural robots. To address these limitations, we introduce FGSeg, a ground segmentation algorithm designed specifically for the agricultural field environment. Our proposed method utilizes only the spatial features of the point cloud data, making it compatible with a wide range of LiDAR sensors. Additionally, FGSeg can effectively distinguish between horizontal and slope terrains, which is crucial for many agricultural operations. The results of extensive experiments demonstrate that our proposed algorithm outperforms existing ground segmentation algorithms in both field and urban environments, and its real-time performance makes it well-suited for practical applications in the agriculture industry.}
}

@article{Geiger2013IJRR,
  author = {Andreas Geiger and Philip Lenz and Christoph Stiller and Raquel Urtasun},
  title = {Vision meets Robotics: The {KITTI} Dataset},
  journal = {International Journal of Robotics Research (IJRR)},
  year = {2013}
} 

@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={652--660},
  year={2017}
}


@article{qi2017pointnet++,
  title={Pointnet++: Deep hierarchical feature learning on point sets in a metric space},
  author={Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{paigwar2020gndnet,
  title={{GndNet}: Fast ground plane estimation and point cloud segmentation for autonomous vehicles},
  author={Paigwar, Anshul and Erkent, {\"O}zg{\"u}r and Sierra-Gonzalez, David and Laugier, Christian},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={2150--2156},
  year={2020},
  organization={IEEE}
}

@inproceedings{lang2019pointpillars,
  title={Pointpillars: Fast encoders for object detection from point clouds},
  author={Lang, Alex H and Vora, Sourabh and Caesar, Holger and Zhou, Lubing and Yang, Jiong and Beijbom, Oscar},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12697--12705},
  year={2019}
}

@INPROCEEDINGS{5650541,
  author={Douillard, B. and Underwood, J. and Melkumyan, N. and Singh, S. and Vasudevan, S. and Brunner, C. and Quadros, A.},
  booktitle={2010 IEEE/RSJ International Conference on Intelligent Robots and Systems}, 
  title={Hybrid elevation maps: 3D surface models for segmentation}, 
  year={2010},
  volume={},
  number={},
  pages={1532-1538},
  keywords={Three dimensional displays;Computational modeling;Laser modes;Noise measurement;Clouds;Buildings;Context},
  doi={10.1109/IROS.2010.5650541}}

  @ARTICLE{9558794,
  author={Anand, Bhaskar and Senapati, Mrinal and Barsaiyan, Vivek and Rajalakshmi, Pachamuthu},
  journal={IEEE Transactions on Instrumentation and Measurement}, 
  title={LiDAR-INS/GNSS-Based Real-Time Ground Removal, Segmentation, and Georeferencing Framework for Smart Transportation}, 
  year={2021},
  volume={70},
  number={},
  pages={1-11},
  keywords={Laser radar;Real-time systems;Smart transportation;Urban areas;Estimation;Meters;Image reconstruction;Light detection and ranging (LiDAR);point cloud;point cloud library (PCL);smart transportation},
  doi={10.1109/TIM.2021.3117661}}

  @INPROCEEDINGS{5164280,
  author={Moosmann, Frank and Pink, Oliver and Stiller, Christoph},
  booktitle={2009 IEEE Intelligent Vehicles Symposium}, 
  title={Segmentation of 3D lidar data in non-flat urban environments using a local convexity criterion}, 
  year={2009},
  volume={},
  number={},
  pages={215-220},
  keywords={Laser radar;Object detection;Signal processing algorithms;Multidimensional signal processing;Roads;Sensor fusion;Vegetation mapping;Information geometry;Optimization methods;Intelligent vehicles},
  doi={10.1109/IVS.2009.5164280}}

  @ARTICLE{9969541,
  author={Guo, Dongbing and Yang, Guohui and Qi, Baoling and Wang, Chunhui},
  journal={IEEE Sensors Journal}, 
  title={A Fast Ground Segmentation Method of LiDAR Point Cloud From Coarse-to-Fine}, 
  year={2023},
  volume={23},
  number={2},
  pages={1357-1367},
  keywords={Point cloud compression;Image segmentation;Laser radar;Sensors;Autonomous vehicles;Fitting;Pipelines;Coarse-to-fine;light detection and ranging (LiDAR);point cloud;segmentation},
  doi={10.1109/JSEN.2022.3225293}}

  @ARTICLE{9410344,
  author={Huang, Weixin and Liang, Huawei and Lin, Linglong and Wang, Zhiling and Wang, Shaobo and Yu, Biao and Niu, Runxin},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={A Fast Point Cloud Ground Segmentation Approach Based on Coarse-To-Fine Markov Random Field}, 
  year={2022},
  volume={23},
  number={7},
  pages={7841-7854},
  keywords={Three-dimensional displays;Laser radar;Feature extraction;Real-time systems;Classification algorithms;Surface topography;Roads;Intelligent vehicles;ground segmentation;coarse-to-fine MRF;graph cut;real-time},
  doi={10.1109/TITS.2021.3073151}}

  @INPROCEEDINGS{7995861,
  author={Rummelhard, Lukas and Paigwar, Anshul and Nègre, Amaury and Laugier, Christian},
  booktitle={2017 IEEE Intelligent Vehicles Symposium (IV)}, 
  title={Ground estimation and point cloud segmentation using SpatioTemporal Conditional Random Field}, 
  year={2017},
  volume={},
  number={},
  pages={1105-1110},
  keywords={Three-dimensional displays;Hidden Markov models;Laser radar;Computational modeling;Roads;Atmospheric modeling;Random variables},
  doi={10.1109/IVS.2017.7995861}}

  @Article{rs13163239,
  AUTHOR = {Shen, Zhihao and Liang, Huawei and Lin, Linglong and Wang, Zhiling and Huang, Weixin and Yu, Jie},
  TITLE = {Fast Ground Segmentation for 3D LiDAR Point Cloud Based on Jump-Convolution-Process},
  JOURNAL = {Remote Sensing},
  VOLUME = {13},
  YEAR = {2021},
  NUMBER = {16},
  ARTICLE-NUMBER = {3239},
  URL = {https://www.mdpi.com/2072-4292/13/16/3239},
  ISSN = {2072-4292},
  ABSTRACT = {LiDAR occupies a vital position in self-driving as the advanced detection technology enables autonomous vehicles (AVs) to obtain much environmental information. Ground segmentation for LiDAR point cloud is a crucial procedure to ensure AVs’ driving safety. However, some current algorithms suffer from embarrassments such as unavailability on complex terrains, excessive time and memory usage, and additional pre-training requirements. The Jump-Convolution-Process (JCP) is proposed to solve these issues. JCP converts the segmentation problem of the 3D point cloud into the smoothing problem of the 2D image and takes little time to improve the segmentation effect significantly. First, the point cloud marked by an improved local feature extraction algorithm is projected onto an RGB image. Then, the pixel value is initialized with the points’ label and continuously updated according to image convolution. Finally, a jump operation is introduced in the convolution process to perform calculations only on the low-confidence points filtered by the credibility propagation algorithm, reducing the time cost. Experiments on three datasets show that our approach has a better segmentation accuracy and terrain adaptability than those of the three existing methods. Meanwhile, the average time for the proposed method to deal with one scan data of 64-beam and 128-beam LiDAR is only 8.61 ms and 15.62 ms, which fully meets the AVs’ requirement for real-time performance.},
  DOI = {10.3390/rs13163239}
  }

@ARTICLE{9691325,
  author={He, Dong and Abid, Furqan and Kim, Young-Min and Kim, Jong-Hwan},
  journal={IEEE Access}, 
  title={SectorGSnet: Sector Learning for Efficient Ground Segmentation of Outdoor LiDAR Point Clouds}, 
  year={2022},
  volume={10},
  number={},
  pages={11938-11946},
  keywords={Point cloud compression;Laser radar;Image segmentation;Three-dimensional displays;Semantics;Convolution;Image restoration;Ground segmentation;semantic segmentation;outdoor point cloud;PointNet;LiDAR},
  doi={10.1109/ACCESS.2022.3146317}}

  @ARTICLE{9466396,
  author={Lim, Hyungtae and Oh, Minho and Myung, Hyun},
  journal={IEEE Robotics and Automation Letters}, 
  title={Patchwork: Concentric Zone-Based Region-Wise Ground Segmentation With Ground Likelihood Estimation Using a 3D LiDAR Sensor}, 
  year={2021},
  volume={6},
  number={4},
  pages={6458-6465},
  keywords={Three-dimensional displays;Robot sensing systems;Estimation;Laser radar;Roads;Cloud computing;Task analysis;Range sensing;mapping;field robots;ground segmentation},
  doi={10.1109/LRA.2021.3093009}}

  @INPROCEEDINGS{9981561,
  author={Lee, Seungjae and Lim, Hyungtae and Myung, Hyun},
  booktitle={2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Patchwork++: Fast and Robust Ground Segmentation Solving Partial Under-Segmentation Using 3D Point Cloud}, 
  year={2022},
  volume={},
  number={},
  pages={13276-13283},
  keywords={Point cloud compression;Solid modeling;Three-dimensional displays;Laser radar;Fitting;Reflection;Sensors},
  doi={10.1109/IROS47612.2022.9981561}}

  @article {Hsunavi.602,
	author = {Hsu, Li-Ta and Huang, Feng and Ng, Hoi-Fung and Zhang, Guohao and Zhong, Yihan and Bai,, Xiwei and Wen, Weisong},
	title = {Hong Kong UrbanNav: An Open-Source Multisensory Dataset for Benchmarking Urban Navigation Algorithms},
	volume = {70},
	number = {4},
	elocation-id = {navi.602},
	year = {2023},
	doi = {10.33012/navi.602},
	publisher = {Institute of Navigation},
	abstract = {Accurate positioning in urban canyons remains a challenging problem. To facilitate the research and development of reliable and precise positioning methods using multiple sensors in urban canyons, we built a multisensory dataset, UrbanNav, collected in diverse, challenging urban scenarios in Hong Kong. The dataset provides multi-sensor data, including data from multi-frequency global navigation satellite system (GNSS) receivers, an inertial measurement unit (IMU), multiple light detection and ranging (lidar) units, and cameras. Meanwhile, the ground truth of the positioning (with centimeter-level accuracy) is postprocessed by commercial software from NovAtel using an integrated GNSS real-time kinematic and fiber optics gyroscope inertial system. In this paper, the sensor systems, spatial and temporal calibration, data formats, and scenario descriptions are presented in detail. Meanwhile, the benchmark performance of several existing positioning methods is provided as a baseline. Based on the evaluations, we conclude that GNSS can provide satisfactory results in a middle-class urban canyon if an appropriate receiver and algorithms are applied. Both visual and lidar odometry are satisfactory in deep urban canyons, whereas tunnels are still a major challenge. Multisensory integration with the aid of an IMU is a promising solution for achieving seamless positioning in cities. The dataset in its entirety can be found on GitHub at https://github.com/IPNL-POLYU/UrbanNavDataset.},
	issn = {0028-1522},
	URL = {https://navi.ion.org/content/70/4/navi.602},
	eprint = {https://navi.ion.org/content/70/4/navi.602.full.pdf},
	journal = {NAVIGATION: Journal of the Institute of Navigation}
}

@INPROCEEDINGS{9560730,
  author={Pfreundschuh, Patrick and Hendrikx, Hubertus F.C. and Reijgwart, Victor and Dubé, Renaud and Siegwart, Roland and Cramariuc, Andrei},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Dynamic Object Aware LiDAR SLAM based on Automatic Generation of Training Data}, 
  year={2021},
  volume={},
  number={},
  pages={11641-11647},
  keywords={Laser radar;Simultaneous localization and mapping;Three-dimensional displays;Heuristic algorithms;Pipelines;Neural networks;Urban areas},
  doi={10.1109/ICRA48506.2021.9560730}}

  @INPROCEEDINGS{9561251,
  author={Jiang, Peng and Osteen, Philip and Wigness, Maggie and Saripalli, Srikanth},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={RELLIS-3D Dataset: Data, Benchmarks and Analysis}, 
  year={2021},
  volume={},
  number={},
  pages={1110-1116},
  keywords={Deep learning;Image segmentation;Three-dimensional displays;Laser radar;Conferences;Semantics;Urban areas},
  doi={10.1109/ICRA48506.2021.9561251}}

  @ARTICLE{10415477,
  author={Liu, Yuanzhi and Fu, Yujia and Qin, Minghui and Xu, Yufeng and Xu, Baoxin and Chen, Fengdong and Goossens, Bart and Sun, Poly Z.H. and Yu, Hongwei and Liu, Chun and Chen, Long and Tao, Wei and Zhao, Hui},
  journal={IEEE Robotics and Automation Letters}, 
  title={BotanicGarden: A High-Quality Dataset for Robot Navigation in Unstructured Natural Environments}, 
  year={2024},
  volume={9},
  number={3},
  pages={2798-2805},
  keywords={Robots;Navigation;Simultaneous localization and mapping;Three-dimensional displays;Global navigation satellite system;Electronic mail;Laser radar;Data sets for SLAM;field robots;data sets for robotic vision;navigation;unstructured environments},
  doi={10.1109/LRA.2024.3359548}}

  @INPROCEEDINGS{linefit,
  author={Himmelsbach, M. and Hundelshausen, Felix v. and Wuensche, H.-J.},
  booktitle={2010 IEEE Intelligent Vehicles Symposium}, 
  title={Fast segmentation of 3D point clouds for ground vehicles}, 
  year={2010},
  volume={},
  number={},
  pages={560-565},
  keywords={Clouds;Land vehicles;Object detection;Laser radar;Mobile robots;Layout;Real time systems;Remotely operated vehicles;Sensor phenomena and characterization;Robot sensing systems},
  doi={10.1109/IVS.2010.5548059}}

  @INPROCEEDINGS{GPF,
  author={Zermas, Dimitris and Izzat, Izzat and Papanikolopoulos, Nikolaos},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Fast segmentation of 3D point clouds: A paradigm on LiDAR data for autonomous vehicle applications}, 
  year={2017},
  volume={},
  number={},
  pages={5067-5073},
  keywords={Three-dimensional displays;Laser radar;Clustering algorithms;Surface treatment;Autonomous vehicles;Automobiles;Pipelines},
  doi={10.1109/ICRA.2017.7989591}}

  @incollection{RANSAC,
title = {Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography},
editor = {Martin A. Fischler and Oscar Firschein},
booktitle = {Readings in Computer Vision},
publisher = {Morgan Kaufmann},
address = {San Francisco (CA)},
pages = {726-740},
year = {1987},
isbn = {978-0-08-051581-6},
doi = {https://doi.org/10.1016/B978-0-08-051581-6.50070-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780080515816500702},
author = {Martin A. Fischler and Robert C. Bolles},
abstract = {A new paradigm, Random Sample Consensus (RANSAC), for fitting a model to experimental data is introduced, RANSAC is capable of interpreting/ smoothing data containing a significant percentage of gross errors, and is thus ideally suited for applications in automated image analysis where interpretation is based on the data provided by error-prone feature detectors. A major portion of this paper describes the application of RANSAC to the Location Determination Problem (LDP): Given an image depicting a set of landmarks with known locations, determine that point in space from which the image was obtained. In response to a RANSAC requirement, new results are derived on the minimum number of landmarks needed to obtain a solution, and algorithms are presented for computing these minimum-landmark solutions in closed form. These results provide the basis for an automatic system that can solve the LDP under difficult viewing and analysis conditions. Implementation details and computational examples are also presented.}
}

@ARTICLE{R-GPF,
  author={Lim, Hyungtae and Hwang, Sungwon and Myung, Hyun},
  journal={IEEE Robotics and Automation Letters}, 
  title={ERASOR: Egocentric Ratio of Pseudo Occupancy-Based Dynamic Object Removal for Static 3D Point Cloud Map Building}, 
  year={2021},
  volume={6},
  number={2},
  pages={2272-2279},
  keywords={Vehicle dynamics;Three-dimensional displays;Buildings;Urban areas;Dynamics;Location awareness;Laser radar;Mapping;range sensing},
  doi={10.1109/LRA.2021.3061363}}

@inproceedings{GPR,
title={Gaussian-Process-Based Real-Time Ground Segmentation for Autonomous Land Vehicles[J]},
author={Chen T , Dai B , Wang R , et al.},
booktitle={Journal of Intelligent and Robotic Systems}, 
year={2014}, 
pages={76(3-4):563-582}
}